{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8a855",
   "metadata": {
    "id": "29c8a855"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9411e08",
   "metadata": {
    "id": "a9411e08"
   },
   "source": [
    "-------\n",
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "QNbxFhFhyovY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNbxFhFhyovY",
    "outputId": "47a34e65-63f2-4340-dfc4-3ce8454299c7"
   },
   "outputs": [],
   "source": [
    "# Setting up google drive \n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc577db",
   "metadata": {
    "id": "cbc577db"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from IPython import display\n",
    "import my_utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "VWiPS1ePxEUY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWiPS1ePxEUY",
    "outputId": "c1d1e8e4-14bb-4170-d6a0-be8ff6b18bf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "transform_1 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_1)\n",
    "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_1)\n",
    "\n",
    "trainDL = DataLoader(cifar_trainset, batch_size, shuffle=True)\n",
    "testDL = DataLoader(cifar_testset, batch_size, shuffle=True)\n",
    "\n",
    "# print(cifar_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "R-PRFSqNyFYb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-PRFSqNyFYb",
    "outputId": "a31367ba-2206-4ef6-8a54-4c421ec80792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(trainDL))[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fd7575",
   "metadata": {
    "id": "d8fd7575"
   },
   "source": [
    "------\n",
    "# Model & Weight Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pUmR9oqJfvdL",
   "metadata": {
    "id": "pUmR9oqJfvdL"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d: # by checking thr type we can init different layers in different ways\n",
    "        torch.nn.init.xavier_uniform_(m.weight)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e4c781",
   "metadata": {
    "id": "e6e4c781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid\n"
     ]
    }
   ],
   "source": [
    "class KKNet(torch.nn.Module):\n",
    "    def __init__(self, num_inputs=3*32*32, num_channels=3, num_outputs=10, num_hidden=[2, 3, 2]):\n",
    "        super(KKNet, self).__init__()\n",
    "        \n",
    "        self.num_inputs, self.num_channels, self.num_outputs, self.num_hidden = num_inputs, num_channels, num_outputs, num_hidden\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        #### Backbone 1\n",
    "\n",
    "        self.a1 = nn.AvgPool2d(3)\n",
    "        self.l1 = nn.Linear(3*10*10, self.num_hidden[0])\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3)\n",
    "\n",
    "        #### Backbone 2\n",
    "\n",
    "        self.a2 = nn.AvgPool2d(2)\n",
    "        self.l2 = nn.Linear(16*15*15, self.num_hidden[1])\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = 3)\n",
    "\n",
    "        #### Backbone 3\n",
    "\n",
    "        self.a3 = nn.AvgPool2d(2)\n",
    "        self.l3 = nn.Linear(32*14*14, self.num_hidden[2])\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 3)\n",
    "\n",
    "        ##### Classifier\n",
    "\n",
    "        self.ac = nn.AvgPool2d(2)\n",
    "\n",
    "        self.f = nn.Flatten()\n",
    "\n",
    "        self.lc1 = nn.Linear(3600, 2048)\n",
    "        self.lc2 = nn.Linear(2048, 860)\n",
    "        self.lc3 = nn.Linear(860, 120)\n",
    "        self.lc4 = nn.Linear(120, self.num_outputs)\n",
    " \n",
    "    def forward(self, x):\n",
    "        #### Backbone 1\n",
    "\n",
    "        out11 = self.a1(x)\n",
    "        out11 = out11.view(-1,3*10*10)\n",
    "        out11 = self.l1(out11)\n",
    "        out11 = self.relu(out11)\n",
    "        out11 = out11.view(-1,self.num_hidden[0],1,1,1)\n",
    "\n",
    "        conv_outputs = []\n",
    "        for _ in range(self.num_hidden[0]):\n",
    "            o = self.conv1(x)\n",
    "#             o = self.relu(o)\n",
    "            conv_outputs.append(o)\n",
    "        out12 = torch.stack(conv_outputs, dim=1)\n",
    "\n",
    "        out12 = out11*out12\n",
    "\n",
    "        out1 = out12.sum(dim=1)\n",
    "        out1 = self.relu(out1)\n",
    "\n",
    "        #### Backbone 2\n",
    "\n",
    "#         out21 = self.a2( out1 )\n",
    "#         out21 = out21.view(-1,16*15*15)\n",
    "#         out21 = self.l2(out21)\n",
    "#         out21 = self.relu(out21)\n",
    "#         out21 = out21.view(-1,self.num_hidden[1],1,1,1)\n",
    "#         conv_outputs = []\n",
    "#         for _ in range(self.num_hidden[1]):\n",
    "#             o = self.conv2( out1 )\n",
    "# #             o = self.relu(o)\n",
    "#             conv_outputs.append(o)\n",
    "#         out22 = torch.stack(conv_outputs, dim=1)\n",
    "\n",
    "#         out22 = out21*out22\n",
    "\n",
    "#         out2 = out22.sum(dim=1)\n",
    "#         out2 = self.relu(out2)\n",
    "\n",
    "        #### Backbone 3\n",
    "        \n",
    "#         out31 = self.a3( out2 )\n",
    "#         out31 = out31.view(-1,32*14*14)\n",
    "#         out31 = self.l3(out31)\n",
    "#         out31 = self.relu(out31)\n",
    "#         out31 = out31.view(-1,self.num_hidden[2],1,1,1)\n",
    "\n",
    "#         conv_outputs = []\n",
    "#         for _ in range(self.num_hidden[2]):\n",
    "#             o = self.conv3( out2 )\n",
    "#             conv_outputs.append(o)\n",
    "#         out32 = torch.stack(conv_outputs, dim=1)\n",
    "\n",
    "#         out32 = out31*out32\n",
    "\n",
    "#         out3 = out32.sum(dim=1)\n",
    "#         out3 = self.relu(out3)\n",
    "\n",
    "        \n",
    "        ##### Classifier\n",
    "\n",
    "        outC = out1\n",
    "        outC = self.ac(outC)\n",
    "\n",
    "        outC = self.f(outC)\n",
    "        # print(\"C\", outC.shape)\n",
    "        outC = self.lc1(outC)\n",
    "        outC = self.relu(outC)\n",
    "        outC = self.lc2(outC)\n",
    "        outC = self.relu(outC)\n",
    "        outC = self.lc3(outC)\n",
    "        outC = self.relu(outC)\n",
    "        outC = self.lc4(outC)\n",
    "#         outC = self.relu(outC)\n",
    "#         outC = self.lc5(outC)\n",
    "\n",
    "        return outC\n",
    "    \n",
    "# Check Model\n",
    "\n",
    "inp = torch.rand(256,3,32,32)\n",
    "model = KKNet()\n",
    "model.apply(init_weights)\n",
    "a = model.forward(inp)\n",
    "print(\"Valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e25f695",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "id": "Ch3Yigg9UDIN",
    "outputId": "3ab4e780-9be6-4de8-da87-4139b9770be3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KKNet(\n",
      "  (relu): ReLU()\n",
      "  (a1): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
      "  (l1): Linear(in_features=300, out_features=2, bias=True)\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (a2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (l2): Linear(in_features=3600, out_features=3, bias=True)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (a3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (l3): Linear(in_features=6272, out_features=2, bias=True)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (ac): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (f): Flatten(start_dim=1, end_dim=-1)\n",
      "  (lc1): Linear(in_features=3600, out_features=2048, bias=True)\n",
      "  (lc2): Linear(in_features=2048, out_features=860, bias=True)\n",
      "  (lc3): Linear(in_features=860, out_features=120, bias=True)\n",
      "  (lc4): Linear(in_features=120, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "input_channels = 3\n",
    "num_outputs = 10\n",
    "modelKK = KKNet()\n",
    "\n",
    "modelKK.apply(init_weights);\n",
    "print(modelKK)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.SGD(modelKK.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ch3Yigg9UDIN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "id": "Ch3Yigg9UDIN",
    "outputId": "3ab4e780-9be6-4de8-da87-4139b9770be3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "mu.train_ch3(modelKK, trainDL, testDL, loss, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G1PEIcYqjzwQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1PEIcYqjzwQ",
    "outputId": "ea39f3a0-5d60-43f3-85f4-86ca526f9ab6"
   },
   "outputs": [],
   "source": [
    "debug = True\n",
    "x3,y3 = next(iter(trainDL))\n",
    "\n",
    "num_inputs = 3*32*32\n",
    "num_outputs = 10\n",
    "num_channels = 3\n",
    "\n",
    "# x3,y3 = next(iter(train_iter))\n",
    "# print(x3.size(), y3.size())\n",
    "\n",
    "# print(inp.dtype)\n",
    "# print(inp.shape)\n",
    "\n",
    "num_inputs = 3\n",
    "# model = Net(num_inputs, num_outputs)\n",
    "model = KKNet()\n",
    "\n",
    "\n",
    "# model = Net(num_inputs, num_channels, num_outputs)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "a = model.forward(inp)\n",
    "\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XHmhE_ZlC4h-",
   "metadata": {
    "id": "XHmhE_ZlC4h-"
   },
   "outputs": [],
   "source": [
    "class LeNet1(torch.nn.Module):\n",
    "    def __init__(self, num_inputs=3, num_outputs=10):\n",
    "        super(LeNet1, self).__init__()\n",
    "        # self.num_inputs = num_inputs\n",
    "        # self.num_outputs = num_outputs\n",
    "\n",
    "        self.Convl1 = nn.Conv2d(num_inputs, 6, kernel_size = 5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Avg1 = nn.AvgPool2d(2, stride=2)\n",
    "        self.Convl2 = nn.Conv2d(6,16,kernel_size = 5)\n",
    "        self.Avg2 = nn.AvgPool2d(2, stride=2)\n",
    "        self.Fltn = nn.Flatten()\n",
    "        self.Linear1 = nn.Linear(400, 120)\n",
    "        self.Linear2 = nn.Linear(120, 84)\n",
    "        self.Linear3 = nn.Linear(84, num_outputs)\n",
    "    def forward(self, x):\n",
    "        out = self.Convl1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.Avg1(out)\n",
    "        out = self.Convl2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.Avg2(out)\n",
    "        #out = self.relu(out)\n",
    "        out = self.Fltn(out)\n",
    "        # print(out.shape)\n",
    "        out = self.Linear1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.Linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.Linear3(out)\n",
    "        # out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ftelSPaAQn8I",
   "metadata": {
    "id": "ftelSPaAQn8I"
   },
   "outputs": [],
   "source": [
    "# debug = False\n",
    "input_channels = 3\n",
    "num_outputs = 10\n",
    "modelKK = LeNet1()\n",
    "\n",
    "modelL1.apply(init_weights);\n",
    "print(modelL1)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.SGD(modelL1.parameters(), lr=lr)\n",
    "\n",
    "num_epochs = 20\n",
    "mu.train_ch3(modelL1, trainDL, testDL, loss, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JYEUxQ3BJC3d",
   "metadata": {
    "id": "JYEUxQ3BJC3d"
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avgpool1(torch.relu(self.conv1(x)))\n",
    "        x = self.avgpool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0EMOB9QljoGX",
   "metadata": {
    "id": "0EMOB9QljoGX"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d: # by checking thr type we can init different layers in different ways\n",
    "        torch.nn.init.xavier_uniform_(m.weight)          \n",
    "\n",
    "input_channels = 3\n",
    "num_outputs = 10\n",
    "model = LeNet()\n",
    "\n",
    "model.apply(init_weights);\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f263c98a",
   "metadata": {
    "id": "f263c98a"
   },
   "source": [
    "----------\n",
    "# Loss Function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a78ceb",
   "metadata": {
    "id": "50a78ceb"
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a299a",
   "metadata": {
    "id": "e24a299a"
   },
   "source": [
    "----------\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xk_xzxKr0Obu",
   "metadata": {
    "id": "xk_xzxKr0Obu"
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "num_epochs = 20\n",
    "mu.train_ch3(model, trainDL, testDL, loss, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db96683",
   "metadata": {
    "id": "1db96683"
   },
   "source": [
    "----------\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0jE-sBD4jW6P",
   "metadata": {
    "id": "0jE-sBD4jW6P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DEQ0kgzujeAq",
   "metadata": {
    "id": "DEQ0kgzujeAq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "YAfdZNd-jXX6",
   "metadata": {
    "id": "YAfdZNd-jXX6"
   },
   "source": [
    "--------\n",
    "# Scratch Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qo6nkup_1enV",
   "metadata": {
    "id": "qo6nkup_1enV"
   },
   "source": [
    "## Shape testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vLqIotaE1hE5",
   "metadata": {
    "id": "vLqIotaE1hE5"
   },
   "source": [
    "## Deployemnt test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300bc559",
   "metadata": {
    "id": "300bc559"
   },
   "outputs": [],
   "source": [
    "# !pip install init\n",
    "# import tarfile, pickle\n",
    "# # from init import *\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive/')\n",
    "\n",
    "# tar_file = tarfile.open(\"/content/drive/My Drive/cifar-10-python.tar.gz\", 'r:gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QPHZ5wS51VXt",
   "metadata": {
    "id": "QPHZ5wS51VXt"
   },
   "outputs": [],
   "source": [
    "# testX2= torch.from_numpy(testX[0:, :, :, :]).to(torch.float32)\n",
    "# testy2 = torch.from_numpy(testy[0:]).to(torch.int64)\n",
    "\n",
    "# print(testy2.size())\n",
    "\n",
    "# testDS2 = TensorDataset(testX2,testy2)\n",
    "# testDL2 = DataLoader(testDS2) \n",
    "\n",
    "# iter_a = iter(testDL2)\n",
    "\n",
    "# t = 0\n",
    "# x = 0\n",
    "\n",
    "# for _ in range(9500):\n",
    "\n",
    "#   X_test, y_test = next(iter_a)\n",
    "#   op = net.forward(X_test)\n",
    "\n",
    "#   _, y_hat = op.max(1)\n",
    "  \n",
    "#   a = y_hat[0] == y_test[0][0]\n",
    "#   t = t+1\n",
    "\n",
    "#   if a:\n",
    "#     x = x+1\n",
    "\n",
    "# print(t, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pa8wRWR81ZdA",
   "metadata": {
    "id": "pa8wRWR81ZdA"
   },
   "source": [
    "## Alternate Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eecb7e9",
   "metadata": {
    "id": "3eecb7e9"
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot\n",
    "# from keras.datasets import cifar10\n",
    "# # load dataset\n",
    "# (trainX, trainy), (testX, testy) = cifar10.load_data()\n",
    "# # trainX = trainX.transpose(0,1)\n",
    "# # testX = testX.transpose(1,3)\n",
    "# # summarize loaded dataset\n",
    "# print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "# print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
    "# # plot first few images\n",
    "\n",
    "# for i in range(9):\n",
    "#     pyplot.subplot(330 + 1 + i)\n",
    "#     pyplot.imshow(trainX[i])\n",
    "\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0af928",
   "metadata": {
    "id": "fb0af928",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # print(trainX)\n",
    "# trainX1 = torch.from_numpy(trainX[0:, :, :, :]).to(torch.float32)\n",
    "# trainy1 = torch.from_numpy(trainy[0:]).to(torch.int64)\n",
    "# trainy1 = trainy1.T[0]\n",
    "# testX1 = torch.from_numpy(testX[0:, :, :, :]).to(torch.float32)\n",
    "# testy1 = torch.from_numpy(testy[0:]).to(torch.int64)\n",
    "\n",
    "# print(trainX1.size())\n",
    "# print(trainy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a2dff",
   "metadata": {
    "id": "1d9a2dff"
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# batch_size = 256\n",
    "\n",
    "# trainDS = TensorDataset(trainX1,trainy1) # create your datset\n",
    "# testDS = TensorDataset(testX1,testy1) # create your datset\n",
    "# trainDL = DataLoader(trainDS, batch_size=batch_size) # create your dataloader\n",
    "# testDL = DataLoader(testDS, batch_size=batch_size) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56f8f3",
   "metadata": {
    "id": "ef56f8f3"
   },
   "outputs": [],
   "source": [
    "# X, y = next(iter(trainDL))\n",
    "# print(X.size())\n",
    "# print(y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
