{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "29c8a855"
      },
      "outputs": [],
      "source": [],
      "id": "29c8a855"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9411e08"
      },
      "source": [
        "-------\n",
        "# Dataset Loading"
      ],
      "id": "a9411e08"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNbxFhFhyovY",
        "outputId": "47a34e65-63f2-4340-dfc4-3ce8454299c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Setting up google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks')"
      ],
      "id": "QNbxFhFhyovY"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cbc577db"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from IPython import display\n",
        "import my_utils as mu"
      ],
      "id": "cbc577db"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWiPS1ePxEUY",
        "outputId": "c1d1e8e4-14bb-4170-d6a0-be8ff6b18bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets \n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "transform_1 = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_1)\n",
        "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_1)\n",
        "\n",
        "trainDL = DataLoader(cifar_trainset, batch_size, shuffle=True)\n",
        "testDL = DataLoader(cifar_testset, batch_size, shuffle=True)\n",
        "\n",
        "# print(cifar_trainset)"
      ],
      "id": "VWiPS1ePxEUY"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "R-PRFSqNyFYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31367ba-2206-4ef6-8a54-4c421ec80792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "print(next(iter(trainDL))[0].shape)"
      ],
      "id": "R-PRFSqNyFYb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8fd7575"
      },
      "source": [
        "------\n",
        "# Model & Weight Initialisation"
      ],
      "id": "d8fd7575"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "e6e4c781"
      },
      "outputs": [],
      "source": [
        "class KKNet(torch.nn.Module):\n",
        "    def __init__(self, num_inputs=3*32*32, num_channels=3, num_outputs=10, num_hidden=[15, 25]):\n",
        "        super(KKNet, self).__init__()\n",
        "        \n",
        "        self.num_inputs, self.num_channels, self.num_outputs, self.num_hidden = num_inputs, num_channels, num_outputs, num_hidden\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        #### Backbone 1\n",
        "\n",
        "        self.a1 = nn.AvgPool2d(3)\n",
        "        self.l1 = nn.Linear(3*10*10, self.num_hidden[0])\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.num_hidden[0], kernel_size = 5)\n",
        "\n",
        "        #### Backbone 2\n",
        "\n",
        "        self.a2 = nn.AvgPool2d(2)\n",
        "        self.l2 = nn.Linear(num_hidden[0]*14*14, self.num_hidden[1])\n",
        "\n",
        "        self.conv2 = nn.Conv2d(self.num_hidden[0], self.num_hidden[1], kernel_size = 5)\n",
        "\n",
        "        ##### Classifier\n",
        "\n",
        "        self.f = nn.Flatten()\n",
        "\n",
        "        self.lc1 = nn.Linear(14400, 1350)\n",
        "        self.lc2 = nn.Linear(1350, 350)\n",
        "        self.lc3 = nn.Linear(350, 120)\n",
        "        self.lc4 = nn.Linear(120, self.num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "        #### Backbone 1\n",
        "\n",
        "        out11 = self.a1(x)\n",
        "        out11 = out11.view(-1,3*10*10)\n",
        "        out11 = self.l1(out11)\n",
        "        out11 = self.relu(out11)\n",
        "        out11 = out11.view(-1,self.num_hidden[0],1,1,1)\n",
        "\n",
        "        conv1_outputs = []\n",
        "        for _ in range(self.num_hidden[0]):\n",
        "            o = self.conv1(x)\n",
        "            o = self.relu(o)\n",
        "            conv1_outputs.append(o)\n",
        "        out12 = torch.stack(conv1_outputs, dim=1)\n",
        "\n",
        "        out12 = out11*out12\n",
        "\n",
        "        out1 = out12.sum(dim=1)\n",
        "\n",
        "        #### Backbone 2\n",
        "\n",
        "        out21 = self.a2( out1 )\n",
        "        out21 = out21.view(-1,self.num_hidden[0]*14*14)\n",
        "        out21 = self.l2(out21)\n",
        "        out21 = self.relu(out21)\n",
        "        out21 = out21.view(-1,self.num_hidden[1],1,1,1)\n",
        "\n",
        "        conv2_outputs = []\n",
        "        for _ in range(self.num_hidden[1]):\n",
        "            o = self.conv2( out1 )\n",
        "            o = self.relu(o)\n",
        "            conv2_outputs.append(o)\n",
        "        out22 = torch.stack(conv2_outputs, dim=1)\n",
        "\n",
        "        out22 = out21*out22\n",
        "\n",
        "        out2 = out22.sum(dim=1)\n",
        "\n",
        "        \n",
        "        ##### Classifier\n",
        "\n",
        "        outC = out2\n",
        "\n",
        "        outC = self.f(outC)\n",
        "\n",
        "        outC = self.lc1(outC)\n",
        "        outC = self.relu(outC)\n",
        "        outC = self.lc2(outC)\n",
        "        outC = self.relu(outC)\n",
        "        outC = self.lc3(outC)\n",
        "        outC = self.relu(outC)\n",
        "        outC = self.lc4(outC)\n",
        "\n",
        "        return outC\n"
      ],
      "id": "e6e4c781"
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d: # by checking thr type we can init different layers in different ways\n",
        "        torch.nn.init.xavier_uniform_(m.weight)          "
      ],
      "metadata": {
        "id": "pUmR9oqJfvdL"
      },
      "id": "pUmR9oqJfvdL",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "G1PEIcYqjzwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49db6ef-e4be-4c46-e35e-62878962b4eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 10])\n"
          ]
        }
      ],
      "source": [
        "debug = True\n",
        "x3,y3 = next(iter(trainDL))\n",
        "\n",
        "num_inputs = 3*32*32\n",
        "num_outputs = 10\n",
        "num_channels = 3\n",
        "\n",
        "# x3,y3 = next(iter(train_iter))\n",
        "# print(x3.size(), y3.size())\n",
        "\n",
        "inp = torch.rand(256,3,32,32)\n",
        "# print(inp.dtype)\n",
        "# print(inp.shape)\n",
        "\n",
        "num_inputs = 3\n",
        "# model = Net(num_inputs, num_outputs)\n",
        "model = KKNet()\n",
        "\n",
        "\n",
        "# model = Net(num_inputs, num_channels, num_outputs)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "a = model.forward(inp)\n",
        "\n",
        "print(a.shape)\n"
      ],
      "id": "G1PEIcYqjzwQ"
    },
    {
      "cell_type": "code",
      "source": [
        "debug = False\n",
        "input_channels = 3\n",
        "num_outputs = 10\n",
        "modelKK = KKNet()\n",
        "\n",
        "modelKK.apply(init_weights);\n",
        "print(modelKK)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "lr = 0.1\n",
        "optimizer = torch.optim.SGD(modelKK.parameters(), lr=lr)\n",
        "\n",
        "num_epochs = 20\n",
        "mu.train_ch3(modelKK, trainDL, testDL, loss, num_epochs, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch3Yigg9UDIN",
        "outputId": "5edbfade-7788-48c3-a968-6dbac97d3004"
      },
      "id": "Ch3Yigg9UDIN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KKNet(\n",
            "  (relu): ReLU()\n",
            "  (a1): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
            "  (l1): Linear(in_features=300, out_features=15, bias=True)\n",
            "  (conv1): Conv2d(3, 15, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (a2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (l2): Linear(in_features=2940, out_features=25, bias=True)\n",
            "  (conv2): Conv2d(15, 25, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (f): Flatten(start_dim=1, end_dim=-1)\n",
            "  (lc1): Linear(in_features=14400, out_features=1350, bias=True)\n",
            "  (lc2): Linear(in_features=1350, out_features=350, bias=True)\n",
            "  (lc3): Linear(in_features=350, out_features=120, bias=True)\n",
            "  (lc4): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet1(torch.nn.Module):\n",
        "    def __init__(self, num_inputs=3, num_outputs=10):\n",
        "        super(LeNet1, self).__init__()\n",
        "        # self.num_inputs = num_inputs\n",
        "        # self.num_outputs = num_outputs\n",
        "\n",
        "        self.Convl1 = nn.Conv2d(num_inputs, 6, kernel_size = 5)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.Avg1 = nn.AvgPool2d(2, stride=2)\n",
        "        self.Convl2 = nn.Conv2d(6,16,kernel_size = 5)\n",
        "        self.Avg2 = nn.AvgPool2d(2, stride=2)\n",
        "        self.Fltn = nn.Flatten()\n",
        "        self.Linear1 = nn.Linear(400, 120)\n",
        "        self.Linear2 = nn.Linear(120, 84)\n",
        "        self.Linear3 = nn.Linear(84, num_outputs)\n",
        "    def forward(self, x):\n",
        "        out = self.Convl1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.Avg1(out)\n",
        "        out = self.Convl2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.Avg2(out)\n",
        "        #out = self.relu(out)\n",
        "        out = self.Fltn(out)\n",
        "        # print(out.shape)\n",
        "        out = self.Linear1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.Linear2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.Linear3(out)\n",
        "        # out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "XHmhE_ZlC4h-"
      },
      "id": "XHmhE_ZlC4h-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# debug = False\n",
        "input_channels = 3\n",
        "num_outputs = 10\n",
        "modelKK = LeNet1()\n",
        "\n",
        "modelL1.apply(init_weights);\n",
        "print(modelL1)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "lr = 0.1\n",
        "optimizer = torch.optim.SGD(modelL1.parameters(), lr=lr)\n",
        "\n",
        "num_epochs = 20\n",
        "mu.train_ch3(modelL1, trainDL, testDL, loss, num_epochs, optimizer)"
      ],
      "metadata": {
        "id": "ftelSPaAQn8I"
      },
      "id": "ftelSPaAQn8I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
        "        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool1(torch.relu(self.conv1(x)))\n",
        "        x = self.avgpool2(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "JYEUxQ3BJC3d"
      },
      "id": "JYEUxQ3BJC3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EMOB9QljoGX"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d: # by checking thr type we can init different layers in different ways\n",
        "        torch.nn.init.xavier_uniform_(m.weight)          \n",
        "\n",
        "input_channels = 3\n",
        "num_outputs = 10\n",
        "model = LeNet()\n",
        "\n",
        "model.apply(init_weights);\n",
        "print(model)"
      ],
      "id": "0EMOB9QljoGX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f263c98a"
      },
      "source": [
        "----------\n",
        "# Loss Function & optimizer"
      ],
      "id": "f263c98a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50a78ceb"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "lr = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
      ],
      "id": "50a78ceb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e24a299a"
      },
      "source": [
        "----------\n",
        "# Training"
      ],
      "id": "e24a299a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk_xzxKr0Obu"
      },
      "outputs": [],
      "source": [
        "debug = False\n",
        "\n",
        "num_epochs = 20\n",
        "mu.train_ch3(model, trainDL, testDL, loss, num_epochs, optimizer)"
      ],
      "id": "xk_xzxKr0Obu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1db96683"
      },
      "source": [
        "----------\n",
        "# Evaluation"
      ],
      "id": "1db96683"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jE-sBD4jW6P"
      },
      "outputs": [],
      "source": [],
      "id": "0jE-sBD4jW6P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEQ0kgzujeAq"
      },
      "outputs": [],
      "source": [],
      "id": "DEQ0kgzujeAq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAfdZNd-jXX6"
      },
      "source": [
        "--------\n",
        "# Scratch Testing"
      ],
      "id": "YAfdZNd-jXX6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo6nkup_1enV"
      },
      "source": [
        "## Shape testing"
      ],
      "id": "qo6nkup_1enV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLqIotaE1hE5"
      },
      "source": [
        "## Deployemnt test"
      ],
      "id": "vLqIotaE1hE5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "300bc559"
      },
      "outputs": [],
      "source": [
        "# !pip install init\n",
        "# import tarfile, pickle\n",
        "# # from init import *\n",
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive/')\n",
        "\n",
        "# tar_file = tarfile.open(\"/content/drive/My Drive/cifar-10-python.tar.gz\", 'r:gz')"
      ],
      "id": "300bc559"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPHZ5wS51VXt"
      },
      "outputs": [],
      "source": [
        "# testX2= torch.from_numpy(testX[0:, :, :, :]).to(torch.float32)\n",
        "# testy2 = torch.from_numpy(testy[0:]).to(torch.int64)\n",
        "\n",
        "# print(testy2.size())\n",
        "\n",
        "# testDS2 = TensorDataset(testX2,testy2)\n",
        "# testDL2 = DataLoader(testDS2) \n",
        "\n",
        "# iter_a = iter(testDL2)\n",
        "\n",
        "# t = 0\n",
        "# x = 0\n",
        "\n",
        "# for _ in range(9500):\n",
        "\n",
        "#   X_test, y_test = next(iter_a)\n",
        "#   op = net.forward(X_test)\n",
        "\n",
        "#   _, y_hat = op.max(1)\n",
        "  \n",
        "#   a = y_hat[0] == y_test[0][0]\n",
        "#   t = t+1\n",
        "\n",
        "#   if a:\n",
        "#     x = x+1\n",
        "\n",
        "# print(t, x)"
      ],
      "id": "QPHZ5wS51VXt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa8wRWR81ZdA"
      },
      "source": [
        "## Alternate Dataset loading"
      ],
      "id": "pa8wRWR81ZdA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eecb7e9"
      },
      "outputs": [],
      "source": [
        "# from matplotlib import pyplot\n",
        "# from keras.datasets import cifar10\n",
        "# # load dataset\n",
        "# (trainX, trainy), (testX, testy) = cifar10.load_data()\n",
        "# # trainX = trainX.transpose(0,1)\n",
        "# # testX = testX.transpose(1,3)\n",
        "# # summarize loaded dataset\n",
        "# print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        "# print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
        "# # plot first few images\n",
        "\n",
        "# for i in range(9):\n",
        "#     pyplot.subplot(330 + 1 + i)\n",
        "#     pyplot.imshow(trainX[i])\n",
        "\n",
        "# pyplot.show()"
      ],
      "id": "3eecb7e9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb0af928",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# # print(trainX)\n",
        "# trainX1 = torch.from_numpy(trainX[0:, :, :, :]).to(torch.float32)\n",
        "# trainy1 = torch.from_numpy(trainy[0:]).to(torch.int64)\n",
        "# trainy1 = trainy1.T[0]\n",
        "# testX1 = torch.from_numpy(testX[0:, :, :, :]).to(torch.float32)\n",
        "# testy1 = torch.from_numpy(testy[0:]).to(torch.int64)\n",
        "\n",
        "# print(trainX1.size())\n",
        "# print(trainy1)"
      ],
      "id": "fb0af928"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d9a2dff"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# batch_size = 256\n",
        "\n",
        "# trainDS = TensorDataset(trainX1,trainy1) # create your datset\n",
        "# testDS = TensorDataset(testX1,testy1) # create your datset\n",
        "# trainDL = DataLoader(trainDS, batch_size=batch_size) # create your dataloader\n",
        "# testDL = DataLoader(testDS, batch_size=batch_size) # create your dataloader"
      ],
      "id": "1d9a2dff"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef56f8f3"
      },
      "outputs": [],
      "source": [
        "# X, y = next(iter(trainDL))\n",
        "# print(X.size())\n",
        "# print(y)"
      ],
      "id": "ef56f8f3"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}